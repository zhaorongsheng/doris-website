"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["551290"],{762803:function(e,n,t){t.r(n),t.d(n,{default:()=>h,frontMatter:()=>a,metadata:()=>i,assets:()=>o,toc:()=>d,contentTitle:()=>l});var i=JSON.parse('{"id":"lakehouse/datalake-building/hive-build","title":"Hive","description":"\x3c!--","source":"@site/versioned_docs/version-2.1/lakehouse/datalake-building/hive-build.md","sourceDirName":"lakehouse/datalake-building","slug":"/lakehouse/datalake-building/hive-build","permalink":"/docs/lakehouse/datalake-building/hive-build","draft":false,"unlisted":false,"tags":[],"version":"2.1","frontMatter":{"title":"Hive","language":"en"},"sidebar":"docs","previous":{"title":"Alibaba Cloud DLF","permalink":"/docs/lakehouse/datalake-analytics/dlf"},"next":{"title":"Iceberg","permalink":"/docs/lakehouse/datalake-building/iceberg-build"}}'),r=t("785893"),s=t("250065");let a={title:"Hive",language:"en"},l=void 0,o={},d=[{value:"Metadata Creation and Deletion",id:"metadata-creation-and-deletion",level:2},{value:"Catalog",id:"catalog",level:3},{value:"Database",id:"database",level:3},{value:"Table",id:"table",level:3},{value:"Data Operations",id:"data-operations",level:2},{value:"INSERT",id:"insert",level:3},{value:"INSERT OVERWRITE",id:"insert-overwrite",level:3},{value:"CTAS (CREATE TABLE AS SELECT)",id:"ctas-create-table-as-select",level:3},{value:"Transaction Mechanism",id:"transaction-mechanism",level:2},{value:"Concurrent Writing Mechanism",id:"concurrent-writing-mechanism",level:3},{value:"HDFS File Operations",id:"hdfs-file-operations",level:3},{value:"Relevant Parameters",id:"relevant-parameters",level:2},{value:"BE",id:"be",level:3}];function c(e){let n={a:"a",admonition:"admonition",blockquote:"blockquote",br:"br",code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.p,{children:"Starting from version 2.1.3, Doris supports DDL and DML operations for Hive. Users can directly create databases and tables in Hive through Doris and write data into Hive tables. With this feature, users can perform complete data queries and write operations on Hive through Doris, further helping to simplify the data lake integrated architecture."}),"\n",(0,r.jsx)(n.p,{children:"This article introduces Hive operations supported in Doris, including syntax and usage notes."}),"\n",(0,r.jsxs)(n.admonition,{type:"tip",children:[(0,r.jsxs)(n.p,{children:["Before using, please set:\n",(0,r.jsx)(n.br,{}),"\nset global enable_nereids_planner = true;"]}),(0,r.jsxs)(n.p,{children:["set global enable_fallback_to_original_planner = false;\n",(0,r.jsx)(n.br,{}),"\nFor clusters upgraded from old versions, these variables may change."]})]}),"\n",(0,r.jsx)(n.h2,{id:"metadata-creation-and-deletion",children:"Metadata Creation and Deletion"}),"\n",(0,r.jsx)(n.h3,{id:"catalog",children:"Catalog"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Create"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'CREATE CATALOG [IF NOT EXISTS] hive PROPERTIES (\n    "type"="hms",\n    "hive.metastore.uris" = "thrift://172.21.16.47:7004",\n    "hadoop.username" = "hadoop",\n    "fs.defaultFS" = "hdfs://172.21.16.47:4007"\n);\n'})}),"\n",(0,r.jsxs)(n.p,{children:["Note, if you need to create Hive tables or write data through Doris, you must explicitly include the ",(0,r.jsx)(n.code,{children:"fs.defaultFS"})," property in the Catalog properties. If creating the Catalog is only for querying, this parameter can be omitted."]}),"\n",(0,r.jsxs)(n.p,{children:["For more parameters, please refer to ",(0,r.jsx)(n.a,{href:"/docs/lakehouse/datalake-analytics/hive",children:"Hive Catalog"})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Drop"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"DROP CATALOG [IF EXISTS] hive;\n"})}),"\n",(0,r.jsx)(n.p,{children:"Deleting a Catalog does not delete any database or table information in Hive. It merely removes the mapping to this Hive cluster in Doris."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"database",children:"Database"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Create"}),"\n",(0,r.jsxs)(n.p,{children:["You can switch to the corresponding Catalog and execute the ",(0,r.jsx)(n.code,{children:"CREATE DATABASE"})," statement:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"SWITCH hive;\nCREATE DATABASE [IF NOT EXISTS] hive_db;\n"})}),"\n",(0,r.jsx)(n.p,{children:"You can also create using the fully qualified name or specify the location, as:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"CREATE DATABASE [IF NOT EXISTS] hive.hive_db;\n\nCREATE DATABASE [IF NOT EXISTS] hive.hive_db\nPROPERTIES ('location'='hdfs://172.21.16.47:4007/path/to/db/');\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Later, you can view the Database's Location information using the ",(0,r.jsx)(n.code,{children:"SHOW CREATE DATABASE"})," command:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"mysql> SHOW CREATE DATABASE hive_db;\n+----------+---------------------------------------------------------------------------------------------+\n| Database | Create Database                                                                             |\n+----------+---------------------------------------------------------------------------------------------+\n| hive_db  | CREATE DATABASE `hive_db` LOCATION 'hdfs://172.21.16.47:4007/usr/hive/warehouse/hive_db.db' |\n+----------+---------------------------------------------------------------------------------------------+\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Drop"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"DROP DATABASE [IF EXISTS] hive.hive_db;\n"})}),"\n",(0,r.jsx)(n.p,{children:"Note that for Hive Databases, all tables within the Database must be deleted first, otherwise an error will occur. This operation will also delete the corresponding Database in Hive."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"table",children:"Table"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Create"}),"\n",(0,r.jsx)(n.p,{children:"Doris supports creating partitioned or non-partitioned tables in Hive."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"-- Create unpartitioned hive table\nCREATE TABLE unpartitioned_table (\n  `col1` BOOLEAN COMMENT 'col1',\n  `col2` INT COMMENT 'col2',\n  `col3` BIGINT COMMENT 'col3',\n  `col4` CHAR(10) COMMENT 'col4',\n  `col5` FLOAT COMMENT 'col5',\n  `col6` DOUBLE COMMENT 'col6',\n  `col7` DECIMAL(9,4) COMMENT 'col7',\n  `col8` VARCHAR(11) COMMENT 'col8',\n  `col9` STRING COMMENT 'col9'\n)  ENGINE=hive\nPROPERTIES (\n  'file_format'='parquet'\n);\n\n-- Create partitioned hive table\n-- The partition columns must be in table's column definition list\nCREATE TABLE partition_table (\n  `col1` BOOLEAN COMMENT 'col1',\n  `col2` INT COMMENT 'col2',\n  `col3` BIGINT COMMENT 'col3',\n  `col4` DECIMAL(2,1) COMMENT 'col4',\n  `pt1` VARCHAR COMMENT 'pt1',\n  `pt2` VARCHAR COMMENT 'pt2'\n)  ENGINE=hive\nPARTITION BY LIST (pt1, pt2) ()\nPROPERTIES (\n  'file_format'='orc',\n  'compression'='zlib'\n);\n\n-- Create text format table(Since 2.1.7 & 3.0.3)\nCREATE TABLE text_table (\n    `id` INT,\n    `name` STRING\n) PROPERTIES (\n    'file_format'='text',\n    'compression'='gzip',\n    'field.delim'='\\t',\n    'line.delim'='\\n',\n    'collection.delim'=';',\n    'mapkey.delim'=':',\n    'serialization.null.format'='\\\\N',\n    'escape.delim'='\\\\'\n);\n"})}),"\n",(0,r.jsxs)(n.p,{children:["After creation, you can view the Hive table creation statement using the ",(0,r.jsx)(n.code,{children:"SHOW CREATE TABLE"})," command."]}),"\n",(0,r.jsx)(n.p,{children:"Note, unlike Hive's table creation statements. In Doris, when creating a Hive partitioned table, the partition columns must also be included in the Table's Schema. At the same time, the partition columns must be at the end of all schemas and in the same order."}),"\n",(0,r.jsxs)(n.admonition,{type:"tip",children:[(0,r.jsxs)(n.p,{children:["For some Hive clusters that enable ACID transaction features by default, after using Doris to create a table, the table attribute ",(0,r.jsx)(n.code,{children:"transactional"})," will be true. However, Doris only supports some features of Hive transaction tables, which may cause the problem that Doris itself cannot read the Hive created by Doris. Therefore, it is necessary to explicitly add: ",(0,r.jsx)(n.code,{children:'"transactional" = "false"'})," in the table creation properties to create a non-transactional Hive table:"]}),(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"CREATE TABLE non_acid_table(\n  `col1` BOOLEAN COMMENT 'col1',\n  `col2` INT COMMENT 'col2',\n  `col3` BIGINT COMMENT 'col3'\n)  ENGINE=hive\nPROPERTIES (\n  'transactional'='false',\n);\n"})})]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Drop"}),"\n",(0,r.jsxs)(n.p,{children:["You can drop a Hive table using the ",(0,r.jsx)(n.code,{children:"DROP TABLE"})," statement. Currently, deleting the table also removes the data, including partition data."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Column Types"}),"\n",(0,r.jsx)(n.p,{children:"The column types used when creating Hive tables in Doris correspond to those in Hive as follows:"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Doris"}),(0,r.jsx)(n.th,{children:"Hive"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"BOOLEAN"}),(0,r.jsx)(n.td,{children:"BOOLEAN"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"TINYINT"}),(0,r.jsx)(n.td,{children:"TINYINT"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"SMALLINT"}),(0,r.jsx)(n.td,{children:"SMALLINT"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"INT"}),(0,r.jsx)(n.td,{children:"INT"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"BIGINT"}),(0,r.jsx)(n.td,{children:"BIGINT"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"DATE"}),(0,r.jsx)(n.td,{children:"DATE"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"DATETIME"}),(0,r.jsx)(n.td,{children:"TIMESTAMP"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"FLOAT"}),(0,r.jsx)(n.td,{children:"FLOAT"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"DOUBLE"}),(0,r.jsx)(n.td,{children:"DOUBLE"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"CHAR"}),(0,r.jsx)(n.td,{children:"CHAR"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"VARCHAR"}),(0,r.jsx)(n.td,{children:"STRING"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"STRING"}),(0,r.jsx)(n.td,{children:"STRING"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"DECIMAL"}),(0,r.jsx)(n.td,{children:"DECIMAL"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"ARRAY"}),(0,r.jsx)(n.td,{children:"ARRAY"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"MAP"}),(0,r.jsx)(n.td,{children:"MAP"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"STRUCT"}),(0,r.jsx)(n.td,{children:"STRUCT"})]})]})]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Column types can only be nullable by default, NOT NULL is not supported."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Hive 3.0 supports setting default values. If you need to set default values, you need to explicitly add ",(0,r.jsx)(n.code,{children:'"hive.version" = "3.0.0"'})," in the Catalog properties."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["After inserting data, if the types are not compatible, such as ",(0,r.jsx)(n.code,{children:"'abc'"})," being inserted into a numeric type, it will be converted to a null value before insertion."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Partitions"}),"\n",(0,r.jsx)(n.p,{children:"The partition types in Hive correspond to the List partition in Doris. Therefore, when creating a Hive partitioned table in Doris, you need to use the List partition table creation statement, but there is no need to explicitly enumerate each partition. When writing data, Doris will automatically create the corresponding Hive partition based on the values of the data."}),"\n",(0,r.jsx)(n.p,{children:"Supports creating single-column or multi-column partitioned tables."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"File Formats"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"ORC (default)"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Parquet"}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Text (supported since version 2.1.7 & 3.0.3)"}),"\n",(0,r.jsx)(n.p,{children:"The Text format also supports the following table properties:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"field.delim"}),": column delimiter. Default ",(0,r.jsx)(n.code,{children:"\\1"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"line.delim"}),": row delimiter. Default ",(0,r.jsx)(n.code,{children:"\\n"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"collection.delim"}),": delimiter between elements in complex types. Default ",(0,r.jsx)(n.code,{children:"\\2"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"mapkey.delim"}),": key value delimiter of Map type. Default ",(0,r.jsx)(n.code,{children:"\\3"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"serialization.null.format"}),": storage format of NULL values. Default ",(0,r.jsx)(n.code,{children:"\\N"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"escape.delim"}),": escape character. Default ",(0,r.jsx)(n.code,{children:"\\"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Compression Formats"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Parquet: snappy(default), zstd, plain. (plain means no compression)"}),"\n",(0,r.jsx)(n.li,{children:"ORC: snappy, zlib(default), zstd, plain. (plain means no compression)"}),"\n",(0,r.jsx)(n.li,{children:"Text: gzip, defalte, bzip2, zstd, lz4, lzo, snappy, plain (default). (plain means no compression)"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Storage Medium"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"HDFS"}),"\n",(0,r.jsx)(n.li,{children:"Object Storage"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"data-operations",children:"Data Operations"}),"\n",(0,r.jsx)(n.p,{children:"Data can be written into Hive tables through INSERT statements."}),"\n",(0,r.jsx)(n.p,{children:"Supports writing to Hive tables created by Doris or existing Hive tables with supported format."}),"\n",(0,r.jsx)(n.p,{children:"For partitioned tables, data will automatically be written to the corresponding partition or new partitions will be created."}),"\n",(0,r.jsx)(n.p,{children:"Currently, writing to specific partitions is not supported."}),"\n",(0,r.jsx)(n.h3,{id:"insert",children:"INSERT"}),"\n",(0,r.jsx)(n.p,{children:"The INSERT operation appends data to the target table. Currently, writing to a specific partition is not supported."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'INSERT INTO hive_tbl values (val1, val2, val3, val4);\nINSERT INTO hive.hive_db.hive_tbl SELECT col1, col2 FROM internal.db1.tbl1;\n\nINSERT INTO hive_tbl(col1, col2) values (val1, val2);\nINSERT INTO hive_tbl(col1, col2, partition_col1, partition_col2) values (1, 2, "beijing", "2023-12-12");\n'})}),"\n",(0,r.jsx)(n.h3,{id:"insert-overwrite",children:"INSERT OVERWRITE"}),"\n",(0,r.jsx)(n.p,{children:"The INSERT OVERWRITE operation completely overwrites the existing data in the table with new data. Currently, writing to a specific partition is not supported."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"INSERT OVERWRITE TABLE VALUES(val1, val2, val3, val4)\nINSERT OVERWRITE TABLE hive.hive_db.hive_tbl(col1, col2) SELECT col1, col2 FROM internal.db1.tbl1;\n"})}),"\n",(0,r.jsx)(n.p,{children:"The semantics of INSERT OVERWRITE is consistent with Hive, and has the following behaviors:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"When the target table is a partitioned table and the source table is empty, the operation will not have any effect. The target table data will not change."}),"\n",(0,r.jsx)(n.li,{children:"When the target table is a non-partitioned table and the source table is empty, the target table will be cleared."}),"\n",(0,r.jsx)(n.li,{children:"Currently, writing to a specified partition is not supported, so INSERT OVERWRITE automatically processes the corresponding target table partition according to the value in the source table. If the target table is a partitioned table, only the partitions involved will be overwritten, and the data of the partitions not involved will not change."}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"ctas-create-table-as-select",children:"CTAS (CREATE TABLE AS SELECT)"}),"\n",(0,r.jsxs)(n.p,{children:["A Hive table can be created and populated with data using the ",(0,r.jsx)(n.code,{children:"CTAS (CREATE TABLE AS SELECT)"})," statement:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"CREATE TABLE hive_ctas ENGINE=hive AS SELECT * FROM other_table;\n"})}),"\n",(0,r.jsx)(n.p,{children:"CTAS supports specifying file formats, partitioning methods, and other information, such as:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:'CREATE TABLE hive_ctas ENGINE=hive\nPARTITION BY LIST (pt1, pt2) ()\nAS SELECT col1,pt1,pt2 FROM part_ctas_src WHERE col1>0;\n\nCREATE TABLE hive.hive_db.hive_ctas (col1,col2,pt1) ENGINE=hive\nPARTITION BY LIST (pt1) ()\nPROPERTIES (\n"file_format"="parquet",\n"compression"="zstd"\n)\nAS SELECT col1,pt1 as col2,pt2 as pt1 FROM test_ctas.part_ctas_src WHERE col1>0;\n'})}),"\n",(0,r.jsx)(n.h2,{id:"transaction-mechanism",children:"Transaction Mechanism"}),"\n",(0,r.jsx)(n.p,{children:"Write operations to Hive are placed in a separate transaction. Until the transaction is committed, the data is not visible externally. Only after committing the transaction do the table's related operations become visible to others."}),"\n",(0,r.jsx)(n.p,{children:"Transactions ensure the atomicity of operations\u2014all operations within a transaction either succeed completely or fail altogether."}),"\n",(0,r.jsx)(n.p,{children:"Transactions do not fully guarantee isolation of operations; they strive to minimize the inconsistency window by separating file system operations from metadata operations on the Hive Metastore."}),"\n",(0,r.jsx)(n.p,{children:"For example, in a transaction involving multiple partition modifications of a Hive table, if the task is divided into two batches, and the first batch is completed but the second batch has not yet started, the partitions from the first batch are already visible externally, and can be read, but the second batch partitions cannot."}),"\n",(0,r.jsx)(n.p,{children:"If any anomalies occur during the transaction commit process, the transaction will be directly rolled back, including modifications to HDFS files and metadata in the Hive Metastore, without requiring further action from the user."}),"\n",(0,r.jsx)(n.h3,{id:"concurrent-writing-mechanism",children:"Concurrent Writing Mechanism"}),"\n",(0,r.jsx)(n.p,{children:"Currently, Doris supports concurrent writing using multiple insert statements. However, it is important to note that users need to control concurrent writing to avoid potential conflicts."}),"\n",(0,r.jsx)(n.p,{children:"As ordinary non-transactional Hive tables lack a complete transaction mechanism. From the Doris transaction mechanism described earlier, we know that the current implementation in Doris can only make efforts to minimize the possible inconsistency time window and cannot guarantee true ACID properties. Therefore, concurrent writing to Hive in Doris may lead to data consistency issues."}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"INSERT"})," Concurrent Operations"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"INSERT"})," is a data append operation. When ",(0,r.jsx)(n.code,{children:"INSERT"})," is executed concurrently, it will not cause conflicts, and the operations will produce the expected results."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.code,{children:"INSERT OVERWRITE"})," Concurrent Operations"]}),"\n",(0,r.jsxs)(n.p,{children:["If ",(0,r.jsx)(n.code,{children:"INSERT OVERWRITE"})," is used for concurrent writing to the same table or partition, it may lead to data loss or corruption, and the result may be uncertain."]}),"\n",(0,r.jsx)(n.p,{children:"There are generally the following solutions:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"For partitioned tables, data can be written into different partitions, and concurrent operations on different partitions will not cause conflicts."}),"\n",(0,r.jsxs)(n.li,{children:["For non-partitioned tables, ",(0,r.jsx)(n.code,{children:"INSERT"})," can be executed simultaneously without using ",(0,r.jsx)(n.code,{children:"INSERT OVERWRITE"}),", thus avoiding conflicts."]}),"\n",(0,r.jsx)(n.li,{children:"For potentially conflicting operations, users need to control on the business side to ensure that only one write operation is being performed at the same time."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"hdfs-file-operations",children:"HDFS File Operations"}),"\n",(0,r.jsxs)(n.p,{children:["Data in Hive tables on HDFS is usually written first to a temporary directory, then operations like ",(0,r.jsx)(n.code,{children:"rename"})," are used to commit the files finally. Here, we detail the specific operations on files in HDFS during different data operations."]}),"\n",(0,r.jsxs)(n.p,{children:["The format of the temporary directory is: ",(0,r.jsx)(n.code,{children:"/tmp/.doris_staging/<username>/<uuid>"})]}),"\n",(0,r.jsxs)(n.p,{children:["The format of the written data file names is: ",(0,r.jsx)(n.code,{children:"<query-id>_<uuid>-<index>.<compress-type>.<file-type>"})]}),"\n",(0,r.jsx)(n.p,{children:"Below, we describe the file operations in various cases."}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Non-partitioned table"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Append"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Target table directory: ",(0,r.jsx)(n.code,{children:"hdfs://ns/usr/hive/warehouse/example.db/table1"})]}),"\n",(0,r.jsxs)(n.li,{children:["Temporary file: ",(0,r.jsx)(n.code,{children:"hdfs://ns/tmp/.doris_staging/root/f02247cb662846038baae272af5eeb05/b35fdbcea3a4e39-86d1f36987ef1492_7e3985bf-9de9-4fc7-b84e-adf11aa08756-0.orc"})]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"During the commit phase, all temporary files are moved to the target table directory."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Overwrite"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Target table directory: ",(0,r.jsx)(n.code,{children:"hdfs://ns/usr/hive/warehouse/example.db/table1"})]}),"\n",(0,r.jsxs)(n.li,{children:["Temporary file: ",(0,r.jsx)(n.code,{children:"hdfs://ns/tmp/.doris_staging/root/f02247cb662846038baae272af5eeb05/b35fdbcea3a4e39-86d1f36987ef1492_7e3985bf-9de9-4fc7-b84e-adf11aa08756-0.orc"})]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Commit phase:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["The target table directory is renamed to a temporary target table directory: ",(0,r.jsx)(n.code,{children:"hdfs://ns/usr/hive/warehouse/example.db/_temp_b35fdbcea3a4e39-86d1f36987ef1492_table1"})]}),"\n",(0,r.jsx)(n.li,{children:"The temporary directory is renamed to the target table directory."}),"\n",(0,r.jsx)(n.li,{children:"The temporary target table directory is deleted."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Partitioned table"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Add (Add to a new partition)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Target table directory: ",(0,r.jsx)(n.code,{children:"hdfs://ns/usr/hive/warehouse/example.db/table2/part_col=2024-01-01"})]}),"\n",(0,r.jsxs)(n.li,{children:["Temporary file: ",(0,r.jsx)(n.code,{children:"hdfs://ns/tmp/.doris_staging/root/a7eac7505d7a42fdb06cb9ef1ea3e912/par1=a/d678a74d232345e0-b659e2fb58e86ffd_549ad677-ee75-4fa1-b8a6-3e821e1dae61-0.orc"})]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"During the commit phase, the temporary directory is renamed to the target table directory."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Append (Write data to an existing partition)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Target table directory: ",(0,r.jsx)(n.code,{children:"hdfs://ns/usr/hive/warehouse/example.db/table2/part_col=2024-01-01"})]}),"\n",(0,r.jsxs)(n.li,{children:["Temporary file: ",(0,r.jsx)(n.code,{children:"hdfs://ns/tmp/.doris_staging/root/a7eac7505d7a42fdb06cb9ef1ea3e912/par1=a/d678a74d232345e0-b659e2fb58e86ffd_549ad677-ee75-4fa1-b8a6-3e821e1dae61-0.orc"})]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"During the commit phase, files from the temporary directory are moved to the target table directory."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Overwrite (Overwrite an existing partition)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Target table directory: ",(0,r.jsx)(n.code,{children:"hdfs://ns/usr/hive/warehouse/example.db/table2/part_col=2024-01-01"})]}),"\n",(0,r.jsxs)(n.li,{children:["Temporary file: ",(0,r.jsx)(n.code,{children:"hdfs://ns/tmp/.doris_staging/root/a7eac7505d7a42fdb06cb9ef1ea3e912/par1=a/d678a74d232345e0-b659e2fb58e86ffd_549ad677-ee75-4fa1-b8a6-3e821e1dae61-0.orc"})]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Commit phase:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["The target table partition directory is renamed to a temporary partition directory: ",(0,r.jsx)(n.code,{children:"hdfs://ns/usr/hive/warehouse/example.db/table2/_temp_d678a74d232345e0-b659e2fb58e86ffd_part_col=2024-01-01"})]}),"\n",(0,r.jsx)(n.li,{children:"The temporary partition directory is renamed to the target table partition directory."}),"\n",(0,r.jsx)(n.li,{children:"The temporary partition directory is deleted."}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"relevant-parameters",children:"Relevant Parameters"}),"\n",(0,r.jsx)(n.h3,{id:"be",children:"BE"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Parameter Name"}),(0,r.jsx)(n.th,{children:"Default Value"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"hive_sink_max_file_size"})}),(0,r.jsx)(n.td,{children:"Maximum file size for data files. When the volume of written data exceeds this size, the current file is closed, and a new file is opened for continued writing."}),(0,r.jsx)(n.td,{children:"1GB"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"table_sink_partition_write_max_partition_nums_per_writer"})}),(0,r.jsx)(n.td,{children:"Maximum number of partitions that can be written by each Instance on a BE node."}),(0,r.jsx)(n.td,{children:"128"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"table_sink_non_partition_write_scaling_data_processed_threshold"})}),(0,r.jsxs)(n.td,{children:["Threshold of data volume for starting scaling-write in non-partitioned tables. For every increase of ",(0,r.jsx)(n.code,{children:"table_sink_non_partition_write_scaling_data_processed_threshold"})," in data volume, a new writer (instance) will be engaged for writing. The scaling-write mechanism aims to use a different number of writers (instances) based on the volume of data to increase the throughput of concurrent writing. When the volume of data is small, it also saves resources and reduces the number of files produced as much as possible."]}),(0,r.jsx)(n.td,{children:"25MB"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"table_sink_partition_write_min_data_processed_rebalance_threshold"})}),(0,r.jsxs)(n.td,{children:["Minimum data volume threshold for triggering rebalance in partitioned tables. If ",(0,r.jsx)(n.code,{children:"current accumulated data volume"})," - ",(0,r.jsx)(n.code,{children:"data volume accumulated since the last rebalance or from the start"})," >= ",(0,r.jsx)(n.code,{children:"table_sink_partition_write_min_data_processed_rebalance_threshold"}),", rebalancing is triggered. If there is a significant difference in the final file sizes, you can reduce this threshold to increase balance. However, too small a threshold may increase the cost of rebalancing and potentially affect performance."]}),(0,r.jsx)(n.td,{children:"25MB"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"table_sink_partition_write_min_partition_data_processed_rebalance_threshold"})}),(0,r.jsxs)(n.td,{children:["Minimum data volume threshold per partition for rebalancing in partitioned tables. If ",(0,r.jsx)(n.code,{children:"current partition's data volume"})," >= ",(0,r.jsx)(n.code,{children:"threshold"})," * ",(0,r.jsx)(n.code,{children:"number of tasks allocated to the current partition"}),", rebalancing for that partition begins. If there is a significant difference in the final file sizes, you can reduce this threshold to increase balance. However, too small a threshold may increase the cost of rebalancing and potentially affect performance."]}),(0,r.jsx)(n.td,{children:"15MB"})]})]})]})]})}function h(e={}){let{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},250065:function(e,n,t){t.d(n,{Z:function(){return l},a:function(){return a}});var i=t(667294);let r={},s=i.createContext(r);function a(e){let n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);